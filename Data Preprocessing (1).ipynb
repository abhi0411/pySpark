{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|       1|\n",
      "|        19|        5|     DL|          14869|        12478|       0|      -8|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "#create session\n",
    "appName = \"data preprocessing in Spark\"\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(appName) \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "flightSchema = StructType([\n",
    "  StructField(\"DayofMonth\", IntegerType(), False),\n",
    "  StructField(\"DayOfWeek\", IntegerType(), False),\n",
    "  StructField(\"Carrier\", StringType(), False),\n",
    "  StructField(\"OriginAirportID\", IntegerType(), False),\n",
    "  StructField(\"DestAirportID\", IntegerType(), False),\n",
    "  StructField(\"DepDelay\", IntegerType(), False),\n",
    "  StructField(\"ArrDelay\", IntegerType(), False),\n",
    "])\n",
    "\n",
    "flights = spark.read.csv('dataset/raw-flight-data.csv', \n",
    "                         schema=flightSchema, header=True, sep=',')\n",
    "flights.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----+--------------------+\n",
      "|airport_id|       city|state|                name|\n",
      "+----------+-----------+-----+--------------------+\n",
      "|     10165|Adak Island|   AK|                Adak|\n",
      "|     10299|  Anchorage|   AK|Ted Stevens Ancho...|\n",
      "+----------+-----------+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "airportSchema = StructType([\n",
    "  StructField(\"airport_id\", IntegerType(), False),\n",
    "  StructField(\"city\", StringType(), False),\n",
    "  StructField(\"state\", StringType(), False),\n",
    "  StructField(\"name\", StringType(), False),\n",
    "])\n",
    "\n",
    "airports = spark.read.csv('dataset/airports.csv', header=True, \n",
    "                          schema=airportSchema)\n",
    "airports.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|          city|count|\n",
      "+--------------+-----+\n",
      "|       Phoenix|90281|\n",
      "|         Omaha|13537|\n",
      "|Raleigh/Durham|28436|\n",
      "+--------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightsByOrigin = flights.join(airports,\n",
    "                               flights.OriginAirportID == \n",
    "                               airports.airport_id).groupBy(\"city\").count()\n",
    "flightsByOrigin.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle duplicate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of original data rows:  2719418\n",
      "number of data rows after deleting duplicated data:  2696983\n",
      "number of duplicated data:  22435\n"
     ]
    }
   ],
   "source": [
    "#count the number of original data rows\n",
    "n1 = flights.count()\n",
    "print(\"number of original data rows: \", n1)\n",
    "#count the number of data rows after deleting duplicated data\n",
    "n2 = flights.dropDuplicates().count()\n",
    "print(\"number of data rows after deleting duplicated data: \", n2)\n",
    "n3 = n1 - n2\n",
    "print(\"number of duplicated data: \", n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|height|\n",
      "+----+---+------+\n",
      "|Rony| 27|   168|\n",
      "|Rony| 15|   165|\n",
      "|Rony| 27|   168|\n",
      "+----+---+------+\n",
      "\n",
      "+----+---+------+\n",
      "|name|age|height|\n",
      "+----+---+------+\n",
      "|Rony| 27|   168|\n",
      "|Rony| 15|   165|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Dataframe and delete duplicates\n",
    "df = spark.createDataFrame([(\"Rony\",27, 168), \n",
    "                            (\"Rony\",15, 165), \n",
    "                            (\"Rony\",27, 168)], \n",
    "                           [\"name\",\"age\",\"height\"])\n",
    "df.show()\n",
    "df.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|height|\n",
      "+----+---+------+\n",
      "|Rony| 15|   165|\n",
      "|Rony| 27|   168|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#by name and age duplicate filter\n",
    "df.dropDuplicates(['name','age']).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Handle missing data\n",
    "Delete row if there is at least one (column) missing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of missing value rows:  46233\n"
     ]
    }
   ],
   "source": [
    "flightsNoMissingValue = flights.dropDuplicates().dropna(\n",
    "    how=\"any\", subset=[\"ArrDelay\", \"DepDelay\"])# use how=\"all\" for all column missing data\n",
    "numberOfMissingValueAny = n1 - flightsNoMissingValue.count()\n",
    "print(\"number of missing value rows: \", numberOfMissingValueAny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|         6|        1|     WN|          10821|        10140|       1|     -22|\n",
      "|         8|        1|     AA|          11298|        10140|       0|       6|\n",
      "|        15|        1|     WN|          14747|        10140|      -6|       3|\n",
      "|        27|        1|     AA|          11298|        10140|     113|     117|\n",
      "|         7|        2|     OO|          12266|        10140|      -3|     -11|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightsNoMissingValue.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+\n",
      "|name| age|height|\n",
      "+----+----+------+\n",
      "|Rony|null|   168|\n",
      "|Rony|  27|   168|\n",
      "|Rony|  15|   165|\n",
      "+----+----+------+\n",
      "\n",
      "+----+---+------+\n",
      "|name|age|height|\n",
      "+----+---+------+\n",
      "|Rony| 27|   168|\n",
      "|Rony| 15|   165|\n",
      "+----+---+------+\n",
      "\n",
      "+----+---+------+\n",
      "|name|age|height|\n",
      "+----+---+------+\n",
      "|Rony| 27|   168|\n",
      "|Rony| 15|   165|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(\"Rony\",27, 168), \n",
    "                            (\"Rony\",15, 165), \n",
    "                            (\"Rony\",None, 168)], \n",
    "                           [\"name\",\"age\",\"height\"])\n",
    "df.dropDuplicates().show()\n",
    "df.dropna().show()\n",
    "df.dropna( how=\"all\",  subset=[\"age\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill the missing data using mean value of each corresponding column data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean ArrDelay:  6.63768791455498\n",
      "mean DepDelay:  10.53686662649788\n",
      "+----------------+\n",
      "|   avg(ArrDelay)|\n",
      "+----------------+\n",
      "|6.63768791455498|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#take mean value\n",
    "meanArrDelay = flights.groupBy().avg(\"ArrDelay\").take(1)[0][0]\n",
    "print(\"mean ArrDelay: \", meanArrDelay)\n",
    "meanDepDelay = flights.groupBy().avg(\"DepDelay\").take(1)[0][0]\n",
    "print(\"mean DepDelay: \", meanDepDelay)\n",
    "#drop duplicated data and fill missing data with mean value\n",
    "flightsCleanData=flights.fillna(\n",
    "    {'ArrDelay': meanArrDelay, 'DepDelay': meanDepDelay})\n",
    "#just for experiment\n",
    "flights.groupBy().avg(\"ArrDelay\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+\n",
      "|name| age|height|\n",
      "+----+----+------+\n",
      "|Rony|  27|   168|\n",
      "|Rony|  15|   165|\n",
      "|toni|null|   168|\n",
      "|toni|  70|   168|\n",
      "+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(\"Rony\",27, 168), \n",
    "                            (\"Rony\",15, 165), \n",
    "                            (\"toni\",None, 168),\n",
    "                           (\"toni\",70, 168)], \n",
    "                           [\"name\",\"age\",\"height\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|   avg(ArrDelay)|\n",
      "+----------------+\n",
      "|6.63768791455498|\n",
      "+----------------+\n",
      "\n",
      "mean ArrDelay:  [Row(avg(age)=37.333333333333336)]\n",
      "mean ArrDelay:  37.333333333333336\n"
     ]
    }
   ],
   "source": [
    "flights.groupBy().avg(\"ArrDelay\").show()\n",
    "\n",
    "meanArrDelay = df.groupBy().avg(\"age\").take(1)\n",
    "print(\"mean ArrDelay: \", meanArrDelay)\n",
    "\n",
    "meanArrDelay = df.groupBy().avg(\"age\").take(2)[0][0]\n",
    "print(\"mean ArrDelay: \", meanArrDelay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+\n",
      "|name| age|height|\n",
      "+----+----+------+\n",
      "|Rony|  27|   168|\n",
      "|Rony|  15|   165|\n",
      "|toni|null|   168|\n",
      "|toni|  70|   168|\n",
      "+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(\"Rony\",27, 168), \n",
    "                            (\"Rony\",15, 165), \n",
    "                            (\"toni\",None, 168),\n",
    "                           (\"toni\",70, 168)], \n",
    "                           [\"name\",\"age\",\"height\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean Age:  37.333333333333336\n"
     ]
    }
   ],
   "source": [
    "meanAge = df.groupBy().avg(\"age\").take(1)[0][0]\n",
    "print(\"mean Age: \", meanAge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|height|\n",
      "+----+---+------+\n",
      "|Rony| 27|   168|\n",
      "|Rony| 15|   165|\n",
      "|toni| 37|   168|\n",
      "|toni| 70|   168|\n",
      "+----+---+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[name: string, age: bigint, height: bigint]>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RonyFillAge=df.fillna(\n",
    "    {'Age': meanAge})\n",
    "\n",
    "RonyFillAge.show()\n",
    "RonyFillAge.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the statistic of our dataÂ¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+\n",
      "|summary|          DepDelay|         ArrDelay|\n",
      "+-------+------------------+-----------------+\n",
      "|  count|           2719418|          2719418|\n",
      "|   mean|10.531448640848888|6.630879842672218|\n",
      "| stddev| 35.91695039008075|38.44200618946938|\n",
      "|    min|               -63|              -94|\n",
      "|    max|              1863|             1845|\n",
      "+-------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightsCleanData.describe('DepDelay','ArrDelay').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can also calculate the correlation between two variables to know whether the varible is related each other or not\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation between departure delay and arrival delay:  0.9393538215572761\n"
     ]
    }
   ],
   "source": [
    "correlation = flightsCleanData.corr('DepDelay', 'ArrDelay')\n",
    "print(\"correlation between departure delay and arrival delay: \", \n",
    "      correlation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
